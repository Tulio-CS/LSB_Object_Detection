### Português

#### Descrição do Projeto

O projeto consiste em um classificador de Língua de Sinais Brasileira utilizando a biblioteca MediaPipe para detecção e reconhecimento de gestos em tempo real. A aplicação captura vídeo da câmera do dispositivo, processa os dados utilizando técnicas de visão computacional fornecidas pelo MediaPipe e classifica os gestos identificados por meio de uma rede neural artificial treinada.

#### Funcionalidades Principais

- **Captura de Vídeo em Tempo Real:** Utiliza a câmera do dispositivo para capturar imagens em tempo real.
  
- **Processamento com MediaPipe:** Integração da MediaPipe para detecção e rastreamento de mãos, essencial para identificar gestos.

- **Classificação com Redes Neurais:** Implementação de uma rede neural treinada para classificar os gestos reconhecidos pela MediaPipe.

#### Estrutura do Repositório

```
.
├── data/
│   └── MediaPipe_KeyPoints.csv    # Keypoints gerados pelo Mediapipe
├── encoders/
│   ├── encoder.pkl                # Label encoder para variaveis categoricas
│   └── scaler.pkl                 # Standart Scaler para variaveis numericas
├── models/
│   ├── Model.h5                   # Modelo de rede neural salvo
│   └── Model.weights.h5           # Pesos para seu modelo de rede neural
├── runs/
│   ├── acc.png                    # Grafico de acuracia no treinamento e validação
│   └── loss.png                   # Grafico de loss no treinamento e validação
└── utils /
    ├── cm.py                      # Script que gera uma matriz de confusão da rede neural
    ├── collect_data.py            # Script que coleta os keypoints e salva em um csv
    ├── train_model.py             # Script que trata os dados, cria a rede neural, treina, avalia e salva o modelo
    └── real_time_prediction.py    # Script que realiza a classificação em tempo real
```

#### Dependências

- MediaPipe
- numpy
- pandas
- TensorFlow
- keras
- Scikitlearn
- OpenCV
- Collections
- joblib
- matplotlib
- seaborn



#### Referências

1. Documentação do MediaPipe: [https://google.github.io/mediapipe/](https://ai.google.dev/edge/mediapipe/solutions/guide?hl=pt-br)
2. Documentação do TensorFlow: [https://www.tensorflow.org/api_docs](https://www.tensorflow.org/api_docs)
3. Documentação do OpenCV: [https://docs.opencv.org/](https://docs.opencv.org/)
4. Documentação do SciKitLearn: [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)
5. Documentação do Numpy: [https://numpy.org/doc/](https://numpy.org/doc/)
6. Documentação Pandas: [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)


---

### English

#### Project Description

The project consists of a Brazilian Sign Language classifier using the MediaPipe library for real-time gesture detection and recognition. The application captures video from the device's camera, processes the data using computer vision techniques provided by MediaPipe, and classifies the identified gestures through a trained artificial neural network.

#### Key Features

- **Real-Time Video Capture:** Uses the device camera to capture real-time images.
  
- **MediaPipe Processing:** Integration of MediaPipe for hand detection and tracking, essential for identifying gestures.

- **Neural Network Classification:** Implementation of a trained neural network to classify gestures recognized by MediaPipe.

#### Repository Structure

```
.
├── data/
│   └── MediaPipe_KeyPoints.csv    # Keypoints generated by MediaPipe
├── encoders/
│   ├── encoder.pkl                # Label encoder for categorical variables
│   └── scaler.pkl                 # Standard Scaler for numerical variables
├── models/
│   ├── Model.h5                   # Saved neural network model
│   └── Model.weights.h5           # Weights for your neural network model
├── runs/
│   ├── acc.png                    # Accuracy plot during training and validation
│   └── loss.png                   # Loss plot during training and validation
└── utils /
    ├── cm.py                      # Script to generate a confusion matrix of the neural network
    ├── collect_data.py            # Script to collect keypoints and save them to a CSV
    ├── train_model.py             # Script to preprocess data, create neural network, train, evaluate, and save the model
    └── real_time_prediction.py    # Script to perform real-time classification
```

#### Dependencies

- MediaPipe
- numpy
- pandas
- TensorFlow
- keras
- Scikitlearn
- OpenCV
- Collections
- joblib
- matplotlib
- seaborn



#### References

1. MediaPipe Documentation: [https://google.github.io/mediapipe/](https://ai.google.dev/edge/mediapipe/solutions/guide?hl=pt-br)
2. TensorFlow Documentation: [https://www.tensorflow.org/api_docs](https://www.tensorflow.org/api_docs)
3. OpenCV Documentation: [https://docs.opencv.org/](https://docs.opencv.org/)
4. SciKitLearn Documentation: [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)
5. Numpy Documentation: [https://numpy.org/doc/](https://numpy.org/doc/)
6. Pandas Documentation: [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)
